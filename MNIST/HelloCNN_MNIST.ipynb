{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow==1.14","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py\nimport matplotlib.pyplot as plt\nimport scipy\nfrom PIL import Image\nfrom scipy import ndimage\nimport math\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":29,"outputs":[{"output_type":"stream","text":"/kaggle/input/digit-recognizer/test.csv\n/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.__version__","execution_count":30,"outputs":[{"output_type":"execute_result","execution_count":30,"data":{"text/plain":"'2.1.0'"},"metadata":{}}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load the data into a dataframe.\ndata  = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ndata.head()","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take X,Y values from the dataframe and reshape it into an image of appr. dimension to use in CNN\nX = data.loc[:,'pixel0':].to_numpy().reshape(42000,28,28,1)\nY = data['label'].to_numpy().reshape(42000,)","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert to one_hot\ndef convert_to_one_hot(Y, C):\n    Y = np.eye(C)[Y.reshape(-1)].T\n    return Y","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split the dataset into train and test(dev). Using 80-20 split because datasize is moderate sized\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.20, random_state=42)\nX_train = X_train/255.\nX_test = X_test/255.\nY_train = convert_to_one_hot(Y_train, 10).T\nY_test = convert_to_one_hot(Y_test, 10).T","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Print the dimensions of the train and test(dev) set to verify.\nprint (\"number of training examples = \" + str(X_train.shape[0]))\nprint (\"number of test examples = \" + str(X_test.shape[0]))\nprint (\"X_train shape: \" + str(X_train.shape))\nprint (\"Y_train shape: \" + str(Y_train.shape))\nprint (\"X_test shape: \" + str(X_test.shape))\nprint (\"Y_test shape: \" + str(Y_test.shape))","execution_count":35,"outputs":[{"output_type":"stream","text":"number of training examples = 33600\nnumber of test examples = 8400\nX_train shape: (33600, 28, 28, 1)\nY_train shape: (33600, 10)\nX_test shape: (8400, 28, 28, 1)\nY_test shape: (8400, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(X_train[2].reshape(28,28))\nprint(Y_train[2])","execution_count":36,"outputs":[{"output_type":"stream","text":"[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load submission X data\nX_out = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\nX_out = X_out.to_numpy().reshape(28000,28,28,1)\nX_out = X_out/255","execution_count":37,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementation Using TensorFlow 1.14"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_placeholders(n_H0, n_W0, n_C0, n_y):\n    \"\"\"\n    Creates the placeholders for the tensorflow session.\n    \n    Arguments:\n    n_H0 -- scalar, height of an input image\n    n_W0 -- scalar, width of an input image\n    n_C0 -- scalar, number of channels of the input\n    n_y -- scalar, number of classes\n        \n    Returns:\n    X -- placeholder for the data input, of shape [None, n_H0, n_W0, n_C0] and dtype \"float\"\n    Y -- placeholder for the input labels, of shape [None, n_y] and dtype \"float\"\n    \"\"\"\n    X = tf.placeholder(\"float32\",[None,n_H0,n_W0,n_C0])\n    Y = tf.placeholder(\"float32\",[None,n_y])\n    \n    return X, Y","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, Y = create_placeholders(64, 64, 3, 6)\nprint (\"X = \" + str(X))\nprint (\"Y = \" + str(Y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_parameters():\n    \"\"\"\n    Initializes weight parameters to build a neural network with tensorflow. The shapes are:\n                        W1 : [4, 4, 1, 8]\n                        W2 : [2, 2, 8, 16]\n    Normally, functions should take values as inputs rather than hard coding.\n    Returns:\n    parameters -- a dictionary of tensors containing W1, W2\n    \"\"\"\n    \n    tf.compat.v1.set_random_seed(1)                              \n    \n    W1 = tf.get_variable(\"W1\",[4,4,1,8],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n    W2 = tf.get_variable(\"W2\",[2,2,8,16],initializer= tf.contrib.layers.xavier_initializer(seed = 0))\n    \n    parameters = {\"W1\": W1,\n                  \"W2\": W2}\n    \n    return parameters","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Check if the function works fine\ntf.reset_default_graph()\nwith tf.compat.v1.Session() as sess_test:\n    parameters = initialize_parameters()\n    init = tf.global_variables_initializer()\n    sess_test.run(init)\n    print(\"W1[1,1,1] = \\n\" + str(parameters[\"W1\"]))\n    print(\"W1.shape: \" + str(parameters[\"W1\"].shape))\n    print(\"\\n\")\n    print(\"W2[1,1,1] = \\n\" + str(parameters[\"W2\"]))\n    print(\"W2.shape: \" + str(parameters[\"W2\"].shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let us define forwaed_propagation for the CNN\n\ndef forward_propagation(X,parameters):\n    \"\"\"\n    Implements the forward propagation for the model:\n    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED\n    \n    Returns:\n    Z3 -- the output of the last LINEAR unit\n    \"\"\"\n    \n    #Get the parameters from the dict\n    W1 = parameters[\"W1\"]\n    W2 = parameters[\"W2\"]\n    \n    #CONV2D: stride of 1, padding 'SAME'\n    Z1 = tf.nn.conv2d(X,W1,strides=[1,1,1,1],padding=\"SAME\")\n    \n    #RELU Activation\n    A1 = tf.nn.relu(Z1)\n    \n    # MAX POOL: window 8*8, stride 8, padding SAME\n    P1 = tf.nn.max_pool(A1,ksize=[1,8,8,1],strides=8,padding=\"SAME\")\n    \n    #CONV2D : filters W2, stride 1, padding 'SAME'\n    Z2 = tf.nn.conv2d(P1,W2,strides=[1,1,1,1],padding=\"SAME\")\n    \n    #RELU Activation\n    A2 = tf.nn.relu(Z2)\n    \n    #MAXPOOL: window 4*4, stride 4, padding 'SAME'\n    P2 = tf.nn.max_pool(A2,ksize=[1,4,4,1],strides=4,padding=\"SAME\")\n    \n    #FLATTEN\n    F = tf.contrib.layers.flatten(P2)\n    \n    #Fully-connected\n    # FULLY-CONNECTED without non-linear activation function (not not call softmax).\n    # 10 neurons in output layer.\n    Z3 = tf.contrib.layers.fully_connected(F,10,activation_fn=None)\n    \n    \n    return Z3   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y = create_placeholders(64, 64, 1, 6)\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(Z3, {X: np.random.randn(2,64,64,1), Y: np.random.randn(2,6)})\n    print(\"Z3 = \\n\" + str(a))\n    print(Z3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_cost(Z3, Y):\n    \"\"\"\n    Computes the cost\n    \n    Arguments:\n    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (number of examples, 6)\n    Y -- \"true\" labels vector placeholder, same shape as Z3\n    \n    Returns:\n    cost - Tensor of the cost function\n    \"\"\"    \n    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=Z3,labels=Y))\n    \n    return cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\n\nwith tf.Session() as sess:\n    np.random.seed(1)\n    X, Y = create_placeholders(64, 64, 1, 10)\n    parameters = initialize_parameters()\n    Z3 = forward_propagation(X, parameters)\n    cost = compute_cost(Z3, Y)\n    init = tf.global_variables_initializer()\n    sess.run(init)\n    a = sess.run(cost, {X: np.random.randn(4,64,64,1), Y: np.random.randn(4,10)})\n    print(\"cost = \" + str(a))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n    \"\"\"\n    Creates a list of random minibatches from (X, Y)\n    \n    Arguments:\n    X -- input data, of shape (input size, number of examples) (m, Hi, Wi, Ci)\n    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples) (m, n_y)\n    mini_batch_size - size of the mini-batches, integer\n    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n    \n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n    \"\"\"\n    \n    m = X.shape[0]                  # number of training examples\n    mini_batches = []\n    np.random.seed(seed)\n    \n    # Step 1: Shuffle (X, Y)\n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[permutation,:,:,:]\n    shuffled_Y = Y[permutation,:]\n\n    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:,:,:]\n        mini_batch_Y = shuffled_Y[k * mini_batch_size : k * mini_batch_size + mini_batch_size,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    # Handling the end case (last mini-batch < mini_batch_size)\n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[num_complete_minibatches * mini_batch_size : m,:,:,:]\n        mini_batch_Y = shuffled_Y[num_complete_minibatches * mini_batch_size : m,:]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Implemente a CNN model using TensorFlow having the following layers\n# CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FC\n\ndef model(X_train,Y_train,X_test,Y_test,learning_rate = 0.009, num_epochs = 100,minibatch_size  = 64, print_cost = True):\n    \"\"\"\n    Arguments:\n    X_train -- training set, of shape (None, 28, 28, 1)\n    Y_train -- test set, of shape (None, n_y = 10)\n    X_test -- training set, of shape (None, 28, 28, 1)\n    Y_test -- test set, of shape (None, n_y = 10)\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    minibatch_size -- size of a minibatch\n    print_cost -- True to print the cost every 100 epochs\n    \n    Returns:\n    train_accuracy -- real number, accuracy on the train set (X_train)\n    test_accuracy -- real number, testing accuracy on the test set (X_test)\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    \n    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n    tf.set_random_seed(1)                             # to keep results consistent (tensorflow seed)\n    seed = 3                                          # to keep results consistent (numpy seed)\n    \n    (m,n_H0,n_W0,n_C0) = X_train.shape\n    n_y = Y_train.shape[1]\n    costs = []                                        # to keep track of costs\n    \n    #Create placeholders of correct shape\n    X, Y = tf.placeholder(\"float32\",[None,n_H0,n_W0,n_C0]),tf.placeholder(\"float32\",[None,n_y])\n    \n    #Initialize the parameters\n    parameters = initialize_parameters()\n    \n    #forward propagate\n    Z3 = forward_propagation(X,parameters)\n    \n    #Compute the cost\n    cost = compute_cost(Z3,Y)\n    \n    #Backpropagation: Use AdamOptimizer\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n    \n    # Initialize all the variables globally\n    init = tf.global_variables_initializer()\n     \n    # Start the session to compute the tensorflow graph\n    with tf.Session() as sess:\n        \n        # Run the initialization\n        sess.run(init)\n        \n        # Do the training loop\n        for epoch in range(num_epochs):\n\n            minibatch_cost = 0.\n            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n            seed = seed + 1\n            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n\n            for minibatch in minibatches:\n\n                # Select a minibatch\n                (minibatch_X, minibatch_Y) = minibatch\n                \"\"\"\n                # IMPORTANT: The line that runs the graph on a minibatch.\n                # Run the session to execute the optimizer and the cost.\n                # The feedict should contain a minibatch for (X,Y).\n                \"\"\"\n                _ , temp_cost = sess.run([optimizer,cost],feed_dict={X:minibatch_X,Y:minibatch_Y})\n                \n                minibatch_cost += temp_cost / num_minibatches\n                \n\n            # Print the cost every epoch\n            if print_cost == True and epoch % 5 == 0:\n                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n            if print_cost == True and epoch % 1 == 0:\n                costs.append(minibatch_cost)\n        \n        \n        # plot the cost\n        plt.plot(np.squeeze(costs))\n        plt.ylabel('cost')\n        plt.xlabel('iterations (per tens)')\n        plt.title(\"Learning rate =\" + str(learning_rate))\n        plt.show()\n\n        # Calculate the correct predictions\n        predict_op = tf.argmax(Z3, 1)\n        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n        \n        # Calculate accuracy on the test set\n        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n        print(accuracy)\n        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n        print(\"Train Accuracy:\", train_accuracy)\n        print(\"Test Accuracy:\", test_accuracy)\n        \n#         Z_test = forward_propagation(X_sub,parameters)\n#         predict_op_test = tf.argmax(Z_test, 1)\n#         test_sub_accuracy = accuracy.eval({X: X_test, Y: Y_test})   \n        \n        return train_accuracy, test_accuracy, parameters\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_, _, parameters = model(X_train, Y_train, X_test, Y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementation Using Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_pred(y_true, y_pred):\n    return K.mean(y_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\n\nimport keras.backend as K\nK.set_image_data_format('channels_last')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def KerasModel(input_shape):\n            \n    \"\"\"\n    Implementation of the HappyModel.\n    \n    Arguments:\n    input_shape -- shape of the images of the dataset\n        (height, width, channels) as a tuple.  \n        Note that this does not include the 'batch' as a dimension.\n        If you have a batch like 'X_train', \n        then you can provide the input_shape using\n        X_train.shape[1:]\n    \n\n    Returns:\n    model -- a Model() instance in Keras\n    \"\"\"\n    \n    \n    # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image!\n    X_input = Input(input_shape)\n\n    X = X_input\n    \n    X = Conv2D(8, (16, 16), strides = (1, 1),padding=\"SAME\", name = 'conv00')(X)\n    #Lets see the effect due to adding BN\n    X = BatchNormalization(axis = 3, name = 'bn00')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D(pool_size=(32, 32),strides=(4,4),padding=\"SAME\", name='max_pool01')(X)\n   \n    X = Conv2D(16, (8, 8), strides = (1, 1),padding=\"SAME\", name = 'conv01')(X)\n    #Lets see the effect due to adding BN\n    X = BatchNormalization(axis = 3, name = 'bn01')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D(pool_size=(16, 16),strides=(8,8),padding=\"SAME\", name='max_pool00')(X)\n    \n    #CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FC\n    X = Conv2D(32, (4, 4), strides = (1, 1),padding=\"SAME\", name = 'conv0')(X)\n    #Lets see the effect due to adding BN\n    X = BatchNormalization(axis = 3, name = 'bn0')(X)\n    X = Activation('relu')(X)\n\n    # MAXPOOL\n    X = MaxPooling2D(pool_size=(8, 8),strides=(8,8),padding=\"SAME\", name='max_pool0')(X)\n    \n    X = Conv2D(64, (2, 2), strides = (1, 1),padding=\"SAME\", name = 'conv1')(X)\n    X = BatchNormalization(axis = 3, name = 'bn1')(X)\n    X = Activation('relu')(X)\n    \n    X = MaxPooling2D(pool_size=(4, 4),strides=(4,4),padding=\"SAME\", name='max_pool1')(X)\n\n    # FLATTEN X (means convert it to a vector) + FULLYCONNECTED\n    X = Flatten()(X)\n    X = Dense(10, activation='softmax', name='fc',  kernel_initializer=\"glorot_uniform\")(X)\n\n    # Create model. This creates your Keras model instance, you'll use this instance to train/test the model.\n    model = Model(inputs = X_input, outputs = X, name='mnistModel')\n    \n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = KerasModel(X_train.shape[1:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=[\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=64,epochs=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compute the accuracy for the dev test\npreds = model.evaluate(X_test,Y_test)\n### END CODE HERE ###\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the submission predictions\npred_out = model.predict(X_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find the label corresponding to max prediction\npred_argmax = np.argmax(pred_out,1)\npred_argmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageId = list(range(1,len(pred_argmax)+1))\ndata_out = {'ImageId':ImageId, 'Label':pred_argmax} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_df = pd.DataFrame(data_out)\nout_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Write to csv\nout_df.to_csv('/kaggle/working/submission_4_64_100.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Yet Another CNN Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Convolution2D, MaxPooling2D, Flatten","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_rows, img_cols = 28, 28\ninput_shape = (img_rows, img_cols, 1)\n\nmodel = Sequential()\nmodel.add(Convolution2D(32, (3, 3), padding=\"same\", activation=\"relu\",input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Convolution2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Convolution2D(64, (3, 3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128,activation = 'relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10))\nmodel.add(Activation('sigmoid'))","execution_count":201,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\nmodel.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics=[\"accuracy\"])","execution_count":202,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,Y_train,batch_size=64,epochs=10)","execution_count":229,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n33600/33600 [==============================] - 4s 108us/step - loss: 0.0033 - accuracy: 0.9990\nEpoch 2/10\n33600/33600 [==============================] - 3s 101us/step - loss: 0.0028 - accuracy: 0.9992\nEpoch 3/10\n33600/33600 [==============================] - 3s 94us/step - loss: 0.0033 - accuracy: 0.9990\nEpoch 4/10\n33600/33600 [==============================] - 3s 101us/step - loss: 0.0030 - accuracy: 0.9991\nEpoch 5/10\n33600/33600 [==============================] - 3s 90us/step - loss: 0.0028 - accuracy: 0.9991\nEpoch 6/10\n33600/33600 [==============================] - 3s 92us/step - loss: 0.0031 - accuracy: 0.9990\nEpoch 7/10\n33600/33600 [==============================] - 3s 100us/step - loss: 0.0029 - accuracy: 0.9991\nEpoch 8/10\n33600/33600 [==============================] - 3s 96us/step - loss: 0.0031 - accuracy: 0.9990\nEpoch 9/10\n33600/33600 [==============================] - 3s 89us/step - loss: 0.0030 - accuracy: 0.9990\nEpoch 10/10\n33600/33600 [==============================] - 3s 90us/step - loss: 0.0032 - accuracy: 0.9990\n","name":"stdout"},{"output_type":"execute_result","execution_count":229,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7fa3acb561d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Compute the accuracy for the dev test\npreds = model.evaluate(X_test,Y_test,batch_size=64)\n### END CODE HERE ###\nprint()\nprint (\"Loss = \" + str(preds[0]))\nprint (\"Test Accuracy = \" + str(preds[1]))","execution_count":230,"outputs":[{"output_type":"stream","text":"8400/8400 [==============================] - 0s 39us/step\n\nLoss = 0.0058585868515011776\nTest Accuracy = 0.9987378120422363\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_out = model.predict_classes(X_out)\npred_out","execution_count":231,"outputs":[{"output_type":"execute_result","execution_count":231,"data":{"text/plain":"array([2, 0, 9, ..., 3, 9, 2])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ImageId = list(range(1,len(pred_out)+1))\ndata_out = {'ImageId':ImageId, 'Label':pred_out} \nout_df = pd.DataFrame(data_out)\nout_df","execution_count":232,"outputs":[{"output_type":"execute_result","execution_count":232,"data":{"text/plain":"       ImageId  Label\n0            1      2\n1            2      0\n2            3      9\n3            4      9\n4            5      3\n...        ...    ...\n27995    27996      9\n27996    27997      7\n27997    27998      3\n27998    27999      9\n27999    28000      2\n\n[28000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>27996</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>27997</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>27998</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>27999</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>28000</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Write to csv\nout_df.to_csv('/kaggle/working/submission_another_arch_7.csv',index=False)","execution_count":233,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}